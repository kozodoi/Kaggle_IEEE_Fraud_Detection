{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA, FastICA, FactorAnalysis\n",
    "from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ HELPER FUNCTIONS\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ RANDOMNESS\n",
    "\n",
    "# seed function\n",
    "def seed_everything(seed = 23):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# set seed\n",
    "seed = 23\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1557933093757,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "7QV5eQHHG4Ud",
    "outputId": "2389881e-8c0a-4518-c185-d0a84d1d4a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 447)\n"
     ]
    }
   ],
   "source": [
    "# import CSV\n",
    "df = pd.read_pickle('../input/data_v1.pkl')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1334,
     "status": "ok",
     "timestamp": 1557933093762,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "hxJatDSBG4Uh",
    "outputId": "9b7dd4d7-fbf6-493b-d23c-25fdbf58ee37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 447)\n",
      "(506691, 447)\n"
     ]
    }
   ],
   "source": [
    "# partitioning\n",
    "train = df[df[target].isnull() == False]\n",
    "test  = df[df[target].isnull() == True]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data\n",
    "train = train.sort_values('TransactionID')\n",
    "test  = test.sort_values('TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = train[target]\n",
    "g = train['DT_M']\n",
    "p = train['ProductCD']\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train shape: (590540, 36)\n",
      "- Test shape: (506691, 36)\n"
     ]
    }
   ],
   "source": [
    "### IMPORT OOF PREDS\n",
    "\n",
    "# which model to stack?\n",
    "model = 'lgb'\n",
    "\n",
    "# threshold\n",
    "min_auc = 90\n",
    "\n",
    "# list names\n",
    "names = sorted(os.listdir('../oof_preds'))\n",
    "names = [n for n in names if int(n[n.rindex('_')+1:-4]) > min_auc]\n",
    "names = [s for s in names if model in s]\n",
    "\n",
    "# preprocessing loop\n",
    "for name in names:\n",
    "\n",
    "    # load preds\n",
    "    tmp_tr = pd.read_csv('../oof_preds/'   + str(name))\n",
    "    tmp_te = pd.read_csv('../submissions/' + str(name))\n",
    "\n",
    "    # sort preds by ID\n",
    "    tmp_tr = tmp_tr.sort_values('TransactionID')\n",
    "    tmp_te = tmp_te.sort_values('TransactionID')\n",
    "\n",
    "    # cbind data\n",
    "    if name == names[0]:  \n",
    "        \n",
    "        tmp_tr.columns = ['TransactionID', name]    \n",
    "        tmp_te.columns = ['TransactionID', name]    \n",
    "        train = tmp_tr \n",
    "        test  = tmp_te\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        del tmp_tr['TransactionID'], tmp_te['TransactionID']\n",
    "        tmp_tr.columns = [name]    \n",
    "        tmp_te.columns = [name]    \n",
    "        train = pd.concat([train, tmp_tr], axis = 1)\n",
    "        test  = pd.concat([test,  tmp_te], axis = 1)\n",
    "        \n",
    "# display information\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### DROP CORRELATED PREDICTIONS\n",
    "\n",
    "# threshold\n",
    "top_p = 0.95\n",
    "\n",
    "# error-based sort\n",
    "col_idx = list(np.argsort([l[-9:-4] for l in list(train.columns)]))\n",
    "train   = train[train.columns[col_idx]]\n",
    "\n",
    "# create correlation matrix\n",
    "corr_matrix = train.rank().corr().abs()\n",
    "lower       = corr_matrix.where(np.tril(np.ones(corr_matrix.shape), k = -1).astype(np.bool))\n",
    "\n",
    "# subset \n",
    "to_drop  = [column for column in lower.columns if any(lower[column] > top_p)]\n",
    "features = [f for f in train.columns if f not in to_drop]\n",
    "print(train.shape)\n",
    "train = train[features]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 33)\n"
     ]
    }
   ],
   "source": [
    "# drop bad features\n",
    "excluded_feats = ['TransactionID', 'DT_M']\n",
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynozDG6yivwQ"
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# settings\n",
    "cores = 24\n",
    "seed  = 999\n",
    "\n",
    "# cross-validation\n",
    "num_folds = 6\n",
    "shuffle   = True\n",
    "\n",
    "# muner of rounds\n",
    "max_rounds = 500\n",
    "stopping   = 100\n",
    "verbose    = 100\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':     'gbdt',\n",
    "    'objective':         'binary',\n",
    "    'metric':            'auc',\n",
    "    'bagging_fraction':  0.9,\n",
    "    'feature_fraction':  0.9,\n",
    "    'lambda_l1':         0.1,\n",
    "    'lambda_l2':         0.1,\n",
    "    'min_split_gain':    0,\n",
    "    'min_child_weight':  0.1,\n",
    "    'min_child_samples': 20,\n",
    "    'silent':            True,\n",
    "    'verbosity':         -1,\n",
    "    'learning_rate':     0.1,\n",
    "    'max_depth':         5,\n",
    "    'num_leaves':        50,\n",
    "    'scale_pos_weight':  1,\n",
    "    'n_estimators':      max_rounds,\n",
    "    'nthread' :          cores,\n",
    "    'random_state':      seed,\n",
    "}\n",
    "\n",
    "# data partitinoing\n",
    "#folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n",
    "folds = GroupKFold(n_splits = num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders\n",
    "clfs = []\n",
    "preds_test   = np.zeros(test.shape[0])\n",
    "preds_oof    = np.zeros(train.shape[0])\n",
    "importances  = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom early stopping: select the best out of 500 iterations...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.962428\tvalid_1's auc: 0.925918\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.956604\tvalid_1's auc: 0.927538\n",
      "----------------------\n",
      "FOLD 1: AUC = 0.927538\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 500 iterations...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.959311\tvalid_1's auc: 0.949928\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.955485\tvalid_1's auc: 0.95034\n",
      "----------------------\n",
      "FOLD 2: AUC = 0.950340\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 500 iterations...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.960063\tvalid_1's auc: 0.947905\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.955652\tvalid_1's auc: 0.948269\n",
      "----------------------\n",
      "FOLD 3: AUC = 0.948269\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 500 iterations...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.960466\tvalid_1's auc: 0.943016\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.952566\tvalid_1's auc: 0.9459\n",
      "----------------------\n",
      "FOLD 4: AUC = 0.945900\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 500 iterations...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.958108\tvalid_1's auc: 0.955054\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.95363\tvalid_1's auc: 0.955349\n",
      "----------------------\n",
      "FOLD 5: AUC = 0.955349\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 500 iterations...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.957897\tvalid_1's auc: 0.959307\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's auc: 0.954274\tvalid_1's auc: 0.959781\n",
      "----------------------\n",
      "FOLD 6: AUC = 0.959781\n",
      "----------------------\n",
      "\n",
      "--------------------------------\n",
      "- OOF AUC = 0.945166\n",
      "- CV TIME = 0.75 min\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "### CROSS-VALIDATION LOOP\n",
    "cv_start  = time.time()\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y, groups = g)):\n",
    "    \n",
    "    # data partitioning\n",
    "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "           \n",
    "    # train lightGBM\n",
    "    print('Custom early stopping: select the best out of %.0f iterations...' % max_rounds)\n",
    "    clf = lgb.LGBMClassifier(**lgb_params) \n",
    "    clf = clf.fit(trn_x, trn_y, \n",
    "                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n",
    "                  eval_metric           = \"auc\", \n",
    "                  early_stopping_rounds = stopping,\n",
    "                  verbose               = verbose)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "    # predict validation from the best iteration\n",
    "    best_iter = clf.best_iteration_\n",
    "       \n",
    "    # predictions\n",
    "    preds_oof[val_idx]    = clf.predict_proba(val_x, num_iteration = best_iter)[:, 1]\n",
    "    preds_test           += clf.predict_proba(test[features], num_iteration = best_iter)[:, 1] / folds.n_splits \n",
    "\n",
    "    ## importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df['Feature'] = features\n",
    "    fold_importance_df['Importance'] = clf.feature_importances_\n",
    "    fold_importance_df['Fold'] = n_fold + 1\n",
    "    importances = pd.concat([importances, fold_importance_df], axis = 0)\n",
    "    \n",
    "    # print performance\n",
    "    print('----------------------')\n",
    "    print('FOLD%2d: AUC = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n",
    "    print('----------------------')\n",
    "    print('')\n",
    "        \n",
    "    # clear memory\n",
    "    del trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# print overall performance    \n",
    "cv_perf = roc_auc_score(y, preds_oof)\n",
    "print('--------------------------------')\n",
    "print('- OOF AUC = %.6f' % cv_perf)\n",
    "print('- CV TIME = {:.2f} min'.format((time.time() - cv_start) / 60))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94517\n"
     ]
    }
   ],
   "source": [
    "############ RECHECK PERFORMANCE  \n",
    "\n",
    "# check performance\n",
    "print(np.round(roc_auc_score(y, preds_oof), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dsi_jeGG4VE"
   },
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Tt_FxCwG4VF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stack_lgb34_94516'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file name\n",
    "model = 'stack_lgb'\n",
    "perf  = str(round(cv_perf, 6))[2:7]\n",
    "name  = model + str(len(features)) + '_' + perf\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.003562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.002702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.002311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.002869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.002078\n",
       "1        3663550  0.003562\n",
       "2        3663551  0.002702\n",
       "3        3663552  0.002311\n",
       "4        3663553  0.002869"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export submission\n",
    "sub = pd.DataFrame({'TransactionID': test['TransactionID'], 'isFraud': preds_test})\n",
    "sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
