{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDg2hoRrG4UL"
   },
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QpPWtHZG4UM"
   },
   "outputs": [],
   "source": [
    "############ LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA, FastICA, FactorAnalysis\n",
    "from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ HELPER FUNCTIONS\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ RANDOMNESS\n",
    "\n",
    "# seed function\n",
    "def seed_everything(seed = 23):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# set seed\n",
    "seed = 23\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NraN1BCPG4Uc"
   },
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 498)\n"
     ]
    }
   ],
   "source": [
    "# import CSV\n",
    "df = pd.read_pickle('../input/data_v8.pkl')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfsTSMBAG4Uf"
   },
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1334,
     "status": "ok",
     "timestamp": 1557933093762,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "hxJatDSBG4Uh",
    "outputId": "9b7dd4d7-fbf6-493b-d23c-25fdbf58ee37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 498)\n",
      "(506691, 498)\n"
     ]
    }
   ],
   "source": [
    "# partitioning\n",
    "train = df[df[target].isnull() == False]\n",
    "test  = df[df[target].isnull() == True]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMbdrUNnG4Uk"
   },
   "outputs": [],
   "source": [
    "# extract target\n",
    "y = train[target]\n",
    "del train[target], test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPX4ljoNG4Un"
   },
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B69Fdhg0G4Uo"
   },
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1557933094450,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "eWm2I0jDG4Uo",
    "outputId": "89ecbd36-3fac-47aa-dc7f-5b04b4d6081a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 491)\n"
     ]
    }
   ],
   "source": [
    "############ FEAUTERS\n",
    "\n",
    "# drop bad features\n",
    "excluded_feats = ['TransactionID', 'TransactionDT',\n",
    "                  'bank_type',\n",
    "                  'uid1', 'uid2', 'uid3', 'uid4', 'uid5', \n",
    "                  'DT', 'DT_D', 'DT_W', 'DT_M', 'DT_hour', \n",
    "                  'DT_day_week', 'DT_day_month', \n",
    "                  'DT_D_total', 'DT_W_total', 'DT_M_total']\n",
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynozDG6yivwQ"
   },
   "outputs": [],
   "source": [
    "############ PARAMETERS\n",
    "\n",
    "# cores\n",
    "cores = 24\n",
    "\n",
    "# cross-validation\n",
    "num_folds = 6\n",
    "shuffle   = True\n",
    "\n",
    "# number of trees\n",
    "max_rounds = 10000\n",
    "stopping   = 200\n",
    "verbose    = 250\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':     'gbdt',\n",
    "    'objective':         'binary',\n",
    "    'metric':            'auc',\n",
    "    'bagging_fraction':  0.9,\n",
    "    'feature_fraction':  0.9,\n",
    "    'lambda_l1':         0.1,\n",
    "    'lambda_l2':         0.1,\n",
    "    'min_split_gain':    0,\n",
    "    'min_child_weight':  0.1,\n",
    "    'min_child_samples': 20,\n",
    "    'silent':            True,\n",
    "    'verbosity':         -1,\n",
    "    'learning_rate':     0.01,\n",
    "    'max_depth':         7,\n",
    "    'num_leaves':        256,\n",
    "    'scale_pos_weight':  1,\n",
    "    'n_estimators':      max_rounds,\n",
    "    'nthread' :          cores,\n",
    "    'random_state':      seed,\n",
    "}\n",
    "\n",
    "\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':cores,\n",
    "                    'learning_rate':0.005,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.8,\n",
    "                    'n_estimators':max_rounds,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': seed,\n",
    "                } \n",
    "\n",
    "\n",
    "# data partitinoing\n",
    "#folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n",
    "folds = GroupKFold(n_splits = num_folds)\n",
    "\n",
    "# SMOTE settings\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#sm = SMOTE(random_state = seed, n_jobs = cores, sampling_strategy = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9usATBLbG4Uv"
   },
   "outputs": [],
   "source": [
    "############ PLACEHOLDERS\n",
    "\n",
    "# placeholders\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "\n",
    "# predictions\n",
    "preds_test   = np.zeros(test.shape[0])\n",
    "preds_oof    = np.zeros(train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnYbk3yBG4Uz"
   },
   "source": [
    "### CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52906,
     "status": "ok",
     "timestamp": 1557933151848,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "XdVpCrqxG4U0",
    "outputId": "d2b165a7-c56b-44c0-b62b-466147db5e22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (453219, 491) (137321, 491)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[250]\ttraining's auc: 0.948289\tvalid_1's auc: 0.886511\n",
      "[500]\ttraining's auc: 0.974465\tvalid_1's auc: 0.900597\n",
      "[750]\ttraining's auc: 0.988018\tvalid_1's auc: 0.908499\n",
      "[1000]\ttraining's auc: 0.994208\tvalid_1's auc: 0.913019\n",
      "[1250]\ttraining's auc: 0.997297\tvalid_1's auc: 0.916442\n",
      "[1500]\ttraining's auc: 0.998737\tvalid_1's auc: 0.918652\n",
      "[1750]\ttraining's auc: 0.99941\tvalid_1's auc: 0.920258\n",
      "[2000]\ttraining's auc: 0.999719\tvalid_1's auc: 0.921383\n",
      "[2250]\ttraining's auc: 0.999866\tvalid_1's auc: 0.922175\n",
      "[2500]\ttraining's auc: 0.999936\tvalid_1's auc: 0.922494\n",
      "[2750]\ttraining's auc: 0.999973\tvalid_1's auc: 0.922985\n",
      "[3000]\ttraining's auc: 0.999988\tvalid_1's auc: 0.923363\n",
      "Early stopping, best iteration is:\n",
      "[2973]\ttraining's auc: 0.999987\tvalid_1's auc: 0.923381\n",
      "--------------------------------\n",
      "FOLD 1: AUC BEFORE PL = 0.923381\n",
      "--------------------------------\n",
      "\n",
      "Data shape: (463353, 491) (137321, 491)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[250]\ttraining's auc: 0.949325\tvalid_1's auc: 0.887099\n",
      "[500]\ttraining's auc: 0.974755\tvalid_1's auc: 0.900524\n",
      "[750]\ttraining's auc: 0.988198\tvalid_1's auc: 0.908716\n",
      "[1000]\ttraining's auc: 0.994322\tvalid_1's auc: 0.913761\n",
      "[1250]\ttraining's auc: 0.997297\tvalid_1's auc: 0.916788\n",
      "[1500]\ttraining's auc: 0.998741\tvalid_1's auc: 0.918974\n",
      "[1750]\ttraining's auc: 0.999402\tvalid_1's auc: 0.92038\n",
      "[2000]\ttraining's auc: 0.999716\tvalid_1's auc: 0.921534\n",
      "[2250]\ttraining's auc: 0.999863\tvalid_1's auc: 0.922322\n",
      "[2500]\ttraining's auc: 0.999935\tvalid_1's auc: 0.922878\n",
      "[2750]\ttraining's auc: 0.999971\tvalid_1's auc: 0.923235\n",
      "[3000]\ttraining's auc: 0.999987\tvalid_1's auc: 0.923376\n",
      "[3250]\ttraining's auc: 0.999995\tvalid_1's auc: 0.92382\n",
      "[3500]\ttraining's auc: 0.999998\tvalid_1's auc: 0.924229\n",
      "[3750]\ttraining's auc: 0.999999\tvalid_1's auc: 0.924293\n",
      "[4000]\ttraining's auc: 1\tvalid_1's auc: 0.924502\n",
      "[4250]\ttraining's auc: 1\tvalid_1's auc: 0.924572\n",
      "[4500]\ttraining's auc: 1\tvalid_1's auc: 0.924632\n",
      "[4750]\ttraining's auc: 1\tvalid_1's auc: 0.924732\n",
      "Early stopping, best iteration is:\n",
      "[4656]\ttraining's auc: 1\tvalid_1's auc: 0.924825\n",
      "--------------------------------\n",
      "FOLD 1: AUC AFTER PL = 0.924825\n",
      "--------------------------------\n",
      "\n",
      "Data shape: (488908, 491) (101632, 491)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[250]\ttraining's auc: 0.94743\tvalid_1's auc: 0.909906\n",
      "[500]\ttraining's auc: 0.973828\tvalid_1's auc: 0.925453\n",
      "[750]\ttraining's auc: 0.988097\tvalid_1's auc: 0.934136\n",
      "[1000]\ttraining's auc: 0.994636\tvalid_1's auc: 0.9379\n",
      "[1250]\ttraining's auc: 0.997616\tvalid_1's auc: 0.940164\n",
      "[1500]\ttraining's auc: 0.998924\tvalid_1's auc: 0.941621\n",
      "[1750]\ttraining's auc: 0.999498\tvalid_1's auc: 0.942462\n",
      "[2000]\ttraining's auc: 0.999758\tvalid_1's auc: 0.94309\n",
      "[2250]\ttraining's auc: 0.999888\tvalid_1's auc: 0.943396\n",
      "[2500]\ttraining's auc: 0.999948\tvalid_1's auc: 0.943748\n",
      "[2750]\ttraining's auc: 0.999977\tvalid_1's auc: 0.944025\n",
      "[3000]\ttraining's auc: 0.99999\tvalid_1's auc: 0.944283\n",
      "[3250]\ttraining's auc: 0.999996\tvalid_1's auc: 0.944339\n",
      "[3500]\ttraining's auc: 0.999999\tvalid_1's auc: 0.944507\n",
      "Early stopping, best iteration is:\n",
      "[3474]\ttraining's auc: 0.999999\tvalid_1's auc: 0.944542\n",
      "--------------------------------\n",
      "FOLD 2: AUC BEFORE PL = 0.944542\n",
      "--------------------------------\n",
      "\n",
      "Data shape: (499042, 491) (101632, 491)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[250]\ttraining's auc: 0.948809\tvalid_1's auc: 0.910021\n",
      "[500]\ttraining's auc: 0.974647\tvalid_1's auc: 0.925864\n",
      "[750]\ttraining's auc: 0.988383\tvalid_1's auc: 0.933248\n",
      "[1000]\ttraining's auc: 0.994641\tvalid_1's auc: 0.935816\n",
      "[1250]\ttraining's auc: 0.997624\tvalid_1's auc: 0.937473\n",
      "[1500]\ttraining's auc: 0.998905\tvalid_1's auc: 0.938964\n",
      "[1750]\ttraining's auc: 0.999479\tvalid_1's auc: 0.940004\n",
      "[2000]\ttraining's auc: 0.999755\tvalid_1's auc: 0.940993\n",
      "[2250]\ttraining's auc: 0.999881\tvalid_1's auc: 0.941938\n",
      "[2500]\ttraining's auc: 0.999946\tvalid_1's auc: 0.94243\n",
      "[2750]\ttraining's auc: 0.999977\tvalid_1's auc: 0.943034\n",
      "[3000]\ttraining's auc: 0.999991\tvalid_1's auc: 0.943437\n",
      "[3250]\ttraining's auc: 0.999996\tvalid_1's auc: 0.943717\n",
      "[3500]\ttraining's auc: 0.999999\tvalid_1's auc: 0.944049\n",
      "[3750]\ttraining's auc: 1\tvalid_1's auc: 0.944406\n",
      "[4000]\ttraining's auc: 1\tvalid_1's auc: 0.944653\n",
      "[4250]\ttraining's auc: 1\tvalid_1's auc: 0.944773\n",
      "[4500]\ttraining's auc: 1\tvalid_1's auc: 0.945041\n",
      "[4750]\ttraining's auc: 1\tvalid_1's auc: 0.945112\n",
      "[5000]\ttraining's auc: 1\tvalid_1's auc: 0.945182\n",
      "Early stopping, best iteration is:\n",
      "[4851]\ttraining's auc: 1\tvalid_1's auc: 0.945157\n",
      "--------------------------------\n",
      "FOLD 2: AUC AFTER PL = 0.945157\n",
      "--------------------------------\n",
      "\n",
      "Data shape: (497955, 491) (92585, 491)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[250]\ttraining's auc: 0.945749\tvalid_1's auc: 0.909243\n",
      "[500]\ttraining's auc: 0.972607\tvalid_1's auc: 0.924787\n",
      "[750]\ttraining's auc: 0.987211\tvalid_1's auc: 0.934313\n",
      "[1000]\ttraining's auc: 0.993862\tvalid_1's auc: 0.939157\n",
      "[1250]\ttraining's auc: 0.997118\tvalid_1's auc: 0.942056\n",
      "[1500]\ttraining's auc: 0.99862\tvalid_1's auc: 0.943674\n",
      "[1750]\ttraining's auc: 0.999359\tvalid_1's auc: 0.944405\n",
      "[2000]\ttraining's auc: 0.999688\tvalid_1's auc: 0.945098\n",
      "[2250]\ttraining's auc: 0.999848\tvalid_1's auc: 0.945587\n",
      "[2500]\ttraining's auc: 0.999925\tvalid_1's auc: 0.945984\n",
      "[2750]\ttraining's auc: 0.999966\tvalid_1's auc: 0.946429\n",
      "[3000]\ttraining's auc: 0.999985\tvalid_1's auc: 0.946584\n",
      "[3250]\ttraining's auc: 0.999994\tvalid_1's auc: 0.946832\n",
      "[3500]\ttraining's auc: 0.999998\tvalid_1's auc: 0.946903\n",
      "[3750]\ttraining's auc: 0.999999\tvalid_1's auc: 0.94693\n",
      "Early stopping, best iteration is:\n",
      "[3619]\ttraining's auc: 0.999998\tvalid_1's auc: 0.947043\n",
      "--------------------------------\n",
      "FOLD 3: AUC BEFORE PL = 0.947043\n",
      "--------------------------------\n",
      "\n",
      "Data shape: (508089, 491) (92585, 491)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[250]\ttraining's auc: 0.945675\tvalid_1's auc: 0.909723\n",
      "[500]\ttraining's auc: 0.973261\tvalid_1's auc: 0.925625\n",
      "[750]\ttraining's auc: 0.987252\tvalid_1's auc: 0.934586\n",
      "[1000]\ttraining's auc: 0.994004\tvalid_1's auc: 0.939409\n",
      "[1250]\ttraining's auc: 0.997231\tvalid_1's auc: 0.942115\n",
      "[1500]\ttraining's auc: 0.998672\tvalid_1's auc: 0.943788\n",
      "[1750]\ttraining's auc: 0.999351\tvalid_1's auc: 0.944643\n",
      "[2000]\ttraining's auc: 0.999687\tvalid_1's auc: 0.945187\n",
      "[2250]\ttraining's auc: 0.999848\tvalid_1's auc: 0.945608\n",
      "[2500]\ttraining's auc: 0.999929\tvalid_1's auc: 0.946082\n",
      "[2750]\ttraining's auc: 0.999966\tvalid_1's auc: 0.946458\n",
      "[3000]\ttraining's auc: 0.999985\tvalid_1's auc: 0.946657\n",
      "[3250]\ttraining's auc: 0.999993\tvalid_1's auc: 0.946877\n",
      "[3500]\ttraining's auc: 0.999997\tvalid_1's auc: 0.947022\n",
      "[3750]\ttraining's auc: 0.999999\tvalid_1's auc: 0.946999\n",
      "Early stopping, best iteration is:\n",
      "[3626]\ttraining's auc: 0.999998\tvalid_1's auc: 0.947092\n",
      "--------------------------------\n",
      "FOLD 3: AUC AFTER PL = 0.947092\n",
      "--------------------------------\n",
      "\n",
      "Data shape: (501214, 491) (89326, 491)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[250]\ttraining's auc: 0.945973\tvalid_1's auc: 0.902713\n",
      "[500]\ttraining's auc: 0.971835\tvalid_1's auc: 0.918559\n",
      "[750]\ttraining's auc: 0.986615\tvalid_1's auc: 0.928004\n",
      "[1000]\ttraining's auc: 0.993566\tvalid_1's auc: 0.93332\n",
      "[1250]\ttraining's auc: 0.996992\tvalid_1's auc: 0.936059\n",
      "[1500]\ttraining's auc: 0.998597\tvalid_1's auc: 0.937508\n",
      "[1750]\ttraining's auc: 0.999337\tvalid_1's auc: 0.937987\n",
      "[2000]\ttraining's auc: 0.99967\tvalid_1's auc: 0.93825\n",
      "[2250]\ttraining's auc: 0.999834\tvalid_1's auc: 0.938411\n",
      "[2500]\ttraining's auc: 0.999918\tvalid_1's auc: 0.938573\n",
      "[2750]\ttraining's auc: 0.999961\tvalid_1's auc: 0.938631\n",
      "Early stopping, best iteration is:\n",
      "[2588]\ttraining's auc: 0.999936\tvalid_1's auc: 0.93875\n",
      "--------------------------------\n",
      "FOLD 4: AUC BEFORE PL = 0.938750\n",
      "--------------------------------\n",
      "\n",
      "Data shape: (511348, 491) (89326, 491)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[250]\ttraining's auc: 0.947202\tvalid_1's auc: 0.899656\n",
      "[500]\ttraining's auc: 0.972313\tvalid_1's auc: 0.915297\n",
      "[750]\ttraining's auc: 0.986769\tvalid_1's auc: 0.923364\n",
      "[1000]\ttraining's auc: 0.993534\tvalid_1's auc: 0.928266\n",
      "[1250]\ttraining's auc: 0.996986\tvalid_1's auc: 0.930545\n",
      "[1500]\ttraining's auc: 0.998588\tvalid_1's auc: 0.931632\n",
      "[1750]\ttraining's auc: 0.999303\tvalid_1's auc: 0.932251\n",
      "[2000]\ttraining's auc: 0.999654\tvalid_1's auc: 0.932551\n",
      "[2250]\ttraining's auc: 0.99983\tvalid_1's auc: 0.932779\n",
      "Early stopping, best iteration is:\n",
      "[2236]\ttraining's auc: 0.999823\tvalid_1's auc: 0.932842\n",
      "--------------------------------\n",
      "FOLD 4: AUC AFTER PL = 0.932842\n",
      "--------------------------------\n",
      "\n",
      "Data shape: (504519, 491) (86021, 491)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[250]\ttraining's auc: 0.945793\tvalid_1's auc: 0.922494\n",
      "[500]\ttraining's auc: 0.972455\tvalid_1's auc: 0.935563\n",
      "[750]\ttraining's auc: 0.986676\tvalid_1's auc: 0.942371\n",
      "[1000]\ttraining's auc: 0.993435\tvalid_1's auc: 0.945754\n",
      "[1250]\ttraining's auc: 0.996946\tvalid_1's auc: 0.947483\n"
     ]
    }
   ],
   "source": [
    "############ CROSS-VALIDATION LOOP\n",
    "cv_start  = time.time()\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y, groups = train['DT_M'])):\n",
    "    \n",
    "    # data partitioning\n",
    "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "    test_x       = test[features]\n",
    "    \n",
    "    ## augment training data with SMOTE\n",
    "    #trn_x[trn_x.columns]  = trn_x[trn_x.columns].apply(pd.to_numeric,   errors = 'coerce')\n",
    "    #val_x[val_x.columns]  = val_x[val_x.columns].apply(pd.to_numeric,   errors = 'coerce')\n",
    "    #test_x[val_x.columns] = test_x[test_x.columns].apply(pd.to_numeric, errors = 'coerce')\n",
    "    #trn_x  = trn_x.replace([np.inf,  -np.inf], np.nan)\n",
    "    #val_x  = val_x.replace([np.inf,  -np.inf], np.nan)\n",
    "    #test_x = test_x.replace([np.inf, -np.inf], np.nan)\n",
    "    #trn_x  = trn_x.fillna(trn_x.median())\n",
    "    #val_x  = val_x.fillna(val_x.median())\n",
    "    #test_x = test_x.fillna(test_x.median())\n",
    "    #trn_x, trn_y = sm.fit_sample(trn_x, trn_y)\n",
    "    #trn_x = pd.DataFrame(trn_x, columns = features)\n",
    "    #trn_y = pd.Series(trn_y)\n",
    "    \n",
    "    # label encoding\n",
    "    trn_x, val_x, test_x = label_encoding(trn_x, val_x, test_x)\n",
    "    \n",
    "    ## remove outliers\n",
    "    #for num_var in num_vars:\n",
    "    #    trn_x[num_var] = trn_x[num_var].replace([np.inf, -np.inf], np.nan)\n",
    "    #    trn_x[num_var] = trn_x[num_var].fillna(trn_x[num_var].median())\n",
    "    #out_idx = (np.abs(scipy.stats.zscore(trn_x[num_vars])) < 20).all(axis = 1) + (trn_y.values == 1)\n",
    "    #trn_x = trn_x[out_idx]\n",
    "    #trn_y = trn_y[out_idx]\n",
    "    \n",
    "    ## scale data\n",
    "    #scaler   = RobustScaler()\n",
    "    #trn_x    = pd.DataFrame(scaler.fit_transform(trn_x), columns = features)\n",
    "    #val_x    = pd.DataFrame(scaler.transform(val_x),     columns = features)\n",
    "    #tmp_test = pd.DataFrame(scaler.transform(test_x),    columns = features)\n",
    "       \n",
    "    ## add noise to train to reduce overfitting\n",
    "    #trn_x += np.random.normal(0, 0.01, trn_x.shape)\n",
    "    \n",
    "    # print data dimensions\n",
    "    print('Data shape:', trn_x.shape, val_x.shape)\n",
    "        \n",
    "    # train lightGBM\n",
    "    clf = lgb.LGBMClassifier(**lgb_params) \n",
    "    clf = clf.fit(trn_x, trn_y, \n",
    "                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n",
    "                  eval_metric           = 'auc', \n",
    "                  early_stopping_rounds = stopping,\n",
    "                  verbose               = verbose)\n",
    "    \n",
    "    # find the best iteration\n",
    "    best_iter = clf.best_iteration_\n",
    "\n",
    "    # save predictions\n",
    "    preds_oof[val_idx] = clf.predict_proba(val_x,  num_iteration = best_iter)[:, 1]\n",
    "    preds_test_tmp     = clf.predict_proba(test_x, num_iteration = best_iter)[:, 1]\n",
    "    \n",
    "    # print performance\n",
    "    print('--------------------------------')\n",
    "    print('FOLD%2d: AUC BEFORE PL = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n",
    "    print('--------------------------------')\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############ PSEUDO-LABELING\n",
    "\n",
    "    # find confident predictions\n",
    "    percent0 = 0.01\n",
    "    percent1 = 0.01\n",
    "    sure_idx = np.where((preds_test_tmp > np.quantile(preds_test_tmp, 1 - percent1)) | (preds_test_tmp < np.quantile(preds_test_tmp, percent0)))\n",
    "\n",
    "    # extract X and Y\n",
    "    y_sure = pd.Series(np.round(preds_test[sure_idx]))\n",
    "    x_sure = test_x.iloc[sure_idx].reset_index(drop = True)\n",
    "\n",
    "    # augment the data\n",
    "    trn_x = pd.concat([trn_x, x_sure], axis = 0)\n",
    "    trn_y = pd.concat([trn_y, y_sure], axis = 0)\n",
    "    print('Data shape:', trn_x.shape, val_x.shape)\n",
    "    \n",
    "    # train lightGBM\n",
    "    clf = lgb.LGBMClassifier(**lgb_params) \n",
    "    clf = clf.fit(trn_x, trn_y, \n",
    "                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n",
    "                  eval_metric           = 'auc', \n",
    "                  early_stopping_rounds = stopping,\n",
    "                  verbose               = verbose)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "    # find the best iteration\n",
    "    best_iter = clf.best_iteration_\n",
    "\n",
    "    # save predictions\n",
    "    preds_oof[val_idx] = clf.predict_proba(val_x,  num_iteration = best_iter)[:, 1]\n",
    "    preds_test        += clf.predict_proba(test_x, num_iteration = best_iter)[:, 1] / folds.n_splits \n",
    "\n",
    "    # importance\n",
    "    fold_importance_df               = pd.DataFrame()\n",
    "    fold_importance_df['Feature']    = features\n",
    "    fold_importance_df['Importance'] = clf.feature_importances_\n",
    "    fold_importance_df['Fold']       = n_fold + 1\n",
    "    importances                      = pd.concat([importances, fold_importance_df], axis = 0)\n",
    "    \n",
    "    # print performance\n",
    "    print('--------------------------------')\n",
    "    print('FOLD%2d: AUC AFTER PL = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n",
    "    print('--------------------------------')\n",
    "    print('')\n",
    "        \n",
    "    # clear memory\n",
    "    del trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# print overall performance    \n",
    "cv_perf = roc_auc_score(y, preds_oof)\n",
    "print('--------------------------------')\n",
    "print('- OOF AUC = %.6f' % cv_perf)\n",
    "print('- CV TIME = {:.2f} min'.format((time.time() - cv_start) / 60))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnYbk3yBG4Uz"
   },
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRJGFSmyG4U3"
   },
   "outputs": [],
   "source": [
    "############ RECHECK PERFORMANCE  \n",
    "\n",
    "# check performance\n",
    "print(np.round(roc_auc_score(y, preds_oof), 5))\n",
    "\n",
    "\n",
    "############ TRACK RESULTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYJPn6jmG4U6"
   },
   "outputs": [],
   "source": [
    "############ VARIABLE IMPORTANCE\n",
    "\n",
    "# load importance    \n",
    "top_feats = 100\n",
    "cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False)[0:top_feats].index\n",
    "importance = importances.loc[importances.Feature.isin(cols)]\n",
    "    \n",
    "# plot variable importance\n",
    "plt.figure(figsize = (10, 15))\n",
    "sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False))\n",
    "plt.tight_layout()\n",
    "plt.savefig('../var_importance.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CONFUSION MATRIX\n",
    "\n",
    "# construct confusion matrx\n",
    "cm = confusion_matrix(y, np.round(preds_oof))\n",
    "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "# plot matrix\n",
    "fig, ax = plt.subplots(figsize = (10, 4))\n",
    "sns.heatmap(cm, cmap = 'Blues', annot = True, lw = 0.5)\n",
    "ax.set_xlabel('Prediction')\n",
    "ax.set_ylabel('Ground Truth')\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dsi_jeGG4VE"
   },
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Tt_FxCwG4VF"
   },
   "outputs": [],
   "source": [
    "# file name\n",
    "model = 'lgb_v8pl'\n",
    "perf  = str(round(cv_perf, 6))[2:7]\n",
    "name  = model + '_' + perf\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [],
   "source": [
    "# export OOF preds\n",
    "oof = pd.DataFrame({'TransactionID': train['TransactionID'], 'isFraud': preds_oof})\n",
    "oof.to_csv('../oof_preds/' + str(name) + '.csv', index = False)\n",
    "oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [],
   "source": [
    "# export submission\n",
    "sub = pd.DataFrame({'TransactionID': test['TransactionID'], 'isFraud': preds_test})\n",
    "sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rank correlation with the best submission\n",
    "from scipy.stats import spearmanr\n",
    "sub  = sub.sort_values('TransactionID')\n",
    "best = pd.read_csv(\"../submissions/BlendSolution.csv\")\n",
    "best = best.sort_values('TransactionID')\n",
    "spearmanr(sub.isFraud, best.isFraud)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code_2_lgb_main.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
