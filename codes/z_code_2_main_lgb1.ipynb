{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDg2hoRrG4UL"
   },
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QpPWtHZG4UM"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA, FastICA, FactorAnalysis\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import copy\n",
    "import scipy.stats\n",
    "import os\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oh1I8GrTG4UT"
   },
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXVmT0uFG4UV"
   },
   "outputs": [],
   "source": [
    "# dark background style\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgOaoV66G4UX"
   },
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JmYH_UjRG4Ua"
   },
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "import functions\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NraN1BCPG4Uc"
   },
   "source": [
    "# 2. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1557933093757,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "7QV5eQHHG4Ud",
    "outputId": "2389881e-8c0a-4518-c185-d0a84d1d4a67"
   },
   "outputs": [],
   "source": [
    "# import CSV\n",
    "df = pd.read_csv('../data/data_v2.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfsTSMBAG4Uf"
   },
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = 'granted_number_of_nights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1334,
     "status": "ok",
     "timestamp": 1557933093762,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "hxJatDSBG4Uh",
    "outputId": "9b7dd4d7-fbf6-493b-d23c-25fdbf58ee37"
   },
   "outputs": [],
   "source": [
    "# partitioning\n",
    "train = df[df[target].isnull() == False]\n",
    "test  = df[df[target].isnull() == True]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMbdrUNnG4Uk"
   },
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = train[target]\n",
    "del train[target], test[target]\n",
    "classes = y.unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPX4ljoNG4Un"
   },
   "source": [
    "# 3. MODELING"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### LOSS FUNCTION\n",
    "def multi_weighted_logloss(y_true, y_preds):\n",
    "    \n",
    "    classes = [0, 1, 2, 3]\n",
    "    class_weight = {0:1, 1:10, 2:100, 3:1000}\n",
    "    \n",
    "    # reshape\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order = 'F')\n",
    "    \n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    \n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a = y_p, a_min = 1e-15, a_max = 1-1e-15)\n",
    "    \n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    \n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis = 0)\n",
    "    \n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis = 0).values.astype(float)\n",
    "    \n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    \n",
    "    return 'wloss', loss, False\n",
    "\n",
    "\n",
    "# recompute weights\n",
    "w = y.value_counts()\n",
    "weights = {i : np.sum(w) / w[i] for i in w.index}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B69Fdhg0G4Uo"
   },
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1557933094450,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "eWm2I0jDG4Uo",
    "outputId": "89ecbd36-3fac-47aa-dc7f-5b04b4d6081a"
   },
   "outputs": [],
   "source": [
    "# drop bad features\n",
    "excluded_feats = ['request_id', 'group_main_requester_id', 'request_backoffice_creator_id', \n",
    "                  'answer_creation_date', 'group_creation_date', 'request_creation_date']\n",
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynozDG6yivwQ"
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# settings\n",
    "cores = -1\n",
    "seed  = 23\n",
    "\n",
    "# cross-validation\n",
    "num_folds = 5\n",
    "shuffle   = True\n",
    "\n",
    "# muner of rounds\n",
    "max_rounds = 1000\n",
    "stopping   = 200\n",
    "verbose    = 100\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':     'gbdt',\n",
    "    'objective':         'multiclass',\n",
    "    'metric':            'multi_logloss',\n",
    "    'num_class':         len(classes),\n",
    "    'bagging_fraction':  0.9,\n",
    "    'feature_fraction':  0.9,\n",
    "    'lambda_l1':         0.1,\n",
    "    'lambda_l2':         0.1,\n",
    "    'min_split_gain':    0,\n",
    "    'min_child_weight':  0.1,\n",
    "    'min_child_samples': 20,\n",
    "    'silent':            True,\n",
    "    'verbosity':         -1,\n",
    "    'learning_rate':     0.1,\n",
    "    'max_depth':         5,\n",
    "    'num_leaves':        50,\n",
    "    'scale_pos_weight':  1,\n",
    "    'n_estimators':      max_rounds,\n",
    "    'nthread' :          cores,\n",
    "    'random_state':      seed,\n",
    "}\n",
    "\n",
    "# data partitinoing\n",
    "folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9usATBLbG4Uv"
   },
   "outputs": [],
   "source": [
    "# placeholders\n",
    "clfs = []\n",
    "valid_perf  = np.zeros(num_folds) \n",
    "importances = pd.DataFrame()\n",
    "\n",
    "#preds_test   = np.zeros(test.shape[0])\n",
    "#preds_oof    = np.zeros(train.shape[0])\n",
    "\n",
    "preds_oof  = np.zeros((len(train), len(classes)))\n",
    "preds_test = np.zeros((len(test),  len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHjOpbmYG4Ux"
   },
   "outputs": [],
   "source": [
    "# SMOTE settings\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#sm = SMOTE(random_state = 23, n_jobs = 10, sampling_strategy = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnYbk3yBG4Uz"
   },
   "source": [
    "### CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52906,
     "status": "ok",
     "timestamp": 1557933151848,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "XdVpCrqxG4U0",
    "outputId": "d2b165a7-c56b-44c0-b62b-466147db5e22"
   },
   "outputs": [],
   "source": [
    "### CROSS-VALIDATION LOOP\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n",
    "    \n",
    "    # data partitioning\n",
    "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "    test_x       = test[features]\n",
    "    \n",
    "    ## remove outliers\n",
    "    #out_idx = (np.abs(scipy.stats.zscore(trn_x)) < 10).all(axis = 1)\n",
    "    #trn_x = trn_x[out_idx]\n",
    "    #trn_y = trn_y[out_idx]\n",
    "    \n",
    "    # scale data\n",
    "    #scaler   = RobustScaler()\n",
    "    #trn_x    = pd.DataFrame(scaler.fit_transform(trn_x), columns = features)\n",
    "    #val_x    = pd.DataFrame(scaler.transform(val_x),     columns = features)\n",
    "    #tmp_test = pd.DataFrame(scaler.transform(test_x),    columns = features)\n",
    "\n",
    "    # augment training data with SMOTE\n",
    "    #trn_x, trn_y = sm.fit_sample(trn_x, trn_y)\n",
    "    #trn_x = pd.DataFrame(trn_x, columns = features)\n",
    "    #trn_y = pd.Series(trn_y)\n",
    "       \n",
    "    # add noise to train to reduce overfitting\n",
    "    #trn_x += np.random.normal(0, 0.01, trn_x.shape)\n",
    "        \n",
    "    # train lightGBM\n",
    "    clf = lgb.LGBMClassifier(**lgb_params) \n",
    "    clf = clf.fit(trn_x, trn_y, \n",
    "                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n",
    "                  early_stopping_rounds = stopping,\n",
    "                  verbose               = verbose,\n",
    "                  sample_weight         = 10**trn_y,\n",
    "                  eval_sample_weight    = [10**trn_y, 10**val_y],\n",
    ")\n",
    "    clfs.append(clf)\n",
    "    \n",
    "    # find the best iteration\n",
    "    best_iter = clf.best_iteration_\n",
    "\n",
    "    # save predictions\n",
    "    #preds_oof[val_idx]    = clf.predict_proba(val_x,  num_iteration = best_iter)[:, 1]\n",
    "    #valid_profit[n_fold]  = log_loss(y, preds_oof)\n",
    "    #preds_test           += clf.predict_proba(test_x, num_iteration = best_iter)[:, 1] / folds.n_splits \n",
    "    \n",
    "    # save predictions\n",
    "    preds_oof[val_idx, :] = clf.predict_proba(val_x, num_iteration = best_iter)\n",
    "    valid_perf[n_fold]    = log_loss(val_y, preds_oof[val_idx, :], sample_weight = 10**val_y)\n",
    "    preds_test           += clf.predict_proba(test_x, num_iteration = best_iter) / folds.n_splits \n",
    "\n",
    "    # importance\n",
    "    fold_importance_df               = pd.DataFrame()\n",
    "    fold_importance_df['Feature']    = features\n",
    "    fold_importance_df['Importance'] = clf.feature_importances_\n",
    "    fold_importance_df['Fold']       = n_fold + 1\n",
    "    importances                      = pd.concat([importances, fold_importance_df], axis = 0)\n",
    "    \n",
    "    # print performance\n",
    "    print('--------------------------------')\n",
    "    print('FOLD%2d: LOGLOSS = %.6f' % (n_fold + 1, valid_perf[n_fold]))\n",
    "    print('--------------------------------')\n",
    "    print('')\n",
    "        \n",
    "    # clear memory\n",
    "    del trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# print overall performance    \n",
    "cv_perf = np.mean(valid_perf)\n",
    "print('--------------------------------')\n",
    "print('MEAN LOGLOSS = %.6f' % cv_perf)\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRJGFSmyG4U3"
   },
   "outputs": [],
   "source": [
    "##### RECHECK PERFORMANCE  \n",
    "\n",
    "# define the competition scorer\n",
    "def competition_scorer(y_true, y_pred):\n",
    "    return 'wloss', log_loss(y_true, y_pred, sample_weight = 10**y_true), False\n",
    "\n",
    "##### RECHECK PERFORMANCE  \n",
    "print(competition_scorer(y, preds_oof))\n",
    "\n",
    "\n",
    "###### TRACKING RESULTS (5 folds, strat = True, seed = 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYJPn6jmG4U6"
   },
   "outputs": [],
   "source": [
    "##### VARIABLE IMPORTANCE\n",
    "\n",
    "# load importance    \n",
    "top_feats = 100\n",
    "cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False)[0:top_feats].index\n",
    "importance = importances.loc[importances.Feature.isin(cols)]\n",
    "    \n",
    "# plot variable importance\n",
    "plt.figure(figsize = (10, 15))\n",
    "sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False))\n",
    "plt.tight_layout()\n",
    "\n",
    "# save plot as pdf\n",
    "plt.savefig('../var_importance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dsi_jeGG4VE"
   },
   "source": [
    "# 4. SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Tt_FxCwG4VF"
   },
   "outputs": [],
   "source": [
    "# file name\n",
    "model = 'lgb_v4'\n",
    "perf  = str(round(cv_perf, 6))[2:7]\n",
    "name  = model + '_' + perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [],
   "source": [
    "# export OOF preds\n",
    "#oof = pd.DataFrame({'id': train['id'], 'duration': preds_oof})\n",
    "#oof.to_csv('../oof_preds/' + str(name) + '.csv', index = False)\n",
    "#oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [],
   "source": [
    "# export submission\n",
    "#sub = pd.DataFrame({'id': test['id'], 'duration': preds_test})\n",
    "#sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "#sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [],
   "source": [
    "# export OOF preds\n",
    "oof = pd.DataFrame(preds_oof)\n",
    "oof.insert(0, column = 'request_id', value = train['request_id'].reset_index(drop = True))\n",
    "oof.to_csv('../oof_preds/' + str(name) + '.csv', index = False)\n",
    "oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cJ8GWH7G4VJ"
   },
   "outputs": [],
   "source": [
    "# export submission\n",
    "sub = pd.DataFrame(preds_test)\n",
    "sub.insert(0, column = 'request_id', value = test['request_id'].reset_index(drop = True))\n",
    "sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "##########\n",
    "########## SUBMIT TO QSCORE\n",
    "\n",
    "\n",
    "import io, math, requests\n",
    "\n",
    "# Get your token from qscore:\n",
    "# 1. Go to https://qscore.datascience-olympics.com/\n",
    "# 2. Chose the competition Data Science Olympics 2019\n",
    "# 3. In the left menu click 'Submissions'\n",
    "# 4. Your token is in the 'Submit from your Python Notebook' tab\n",
    "\n",
    "def submit_prediction(df, sep=',', comment='', compression='gzip', **kwargs):\n",
    "    TOKEN='434de6aeb7c04d6298f0d6b9e075e736903794bc342e69b650996ad064e78d5456b3491de344141180dbba9bfab85501c5e515a4c83c1427115ab8fed95a1a20'\n",
    "    URL='https://qscore.datascience-olympics.com/api/submissions'\n",
    "    df.to_csv('temporary.dat', sep=sep, compression=compression, **kwargs)\n",
    "    r = requests.post(URL, headers={'Authorization': 'Bearer {}'.format(TOKEN)},files={'datafile': open('temporary.dat', 'rb')},data={'comment':comment, 'compression': compression})\n",
    "    if r.status_code == 429:\n",
    "        raise Exception('Submissions are too close. Next submission is only allowed in {} seconds.'.format(int(math.ceil(int(r.headers['x-rate-limit-remaining']) / 1000.0))))\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit to QSCORE\n",
    "comment = ''\n",
    "submit_prediction(sub, sep = ',', index = False, comment = str(comment) + ' - ' + name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code_2_lgb_main.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
