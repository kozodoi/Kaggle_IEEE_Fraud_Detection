{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA, FastICA, FactorAnalysis\n",
    "from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ HELPER FUNCTIONS\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ RANDOMNESS\n",
    "\n",
    "# seed function\n",
    "def seed_everything(seed = 23):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# set seed\n",
    "seed = 23\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1557933093757,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "7QV5eQHHG4Ud",
    "outputId": "2389881e-8c0a-4518-c185-d0a84d1d4a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 498)\n"
     ]
    }
   ],
   "source": [
    "# import CSV\n",
    "df = pd.read_pickle('../input/data_v8.pkl')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1334,
     "status": "ok",
     "timestamp": 1557933093762,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "hxJatDSBG4Uh",
    "outputId": "9b7dd4d7-fbf6-493b-d23c-25fdbf58ee37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 498)\n",
      "(506691, 498)\n"
     ]
    }
   ],
   "source": [
    "# partitioning\n",
    "train_df = df[df[target].isnull() == False]\n",
    "test_df  = df[df[target].isnull() == True]\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data\n",
    "train_df = train_df.sort_values('TransactionID')\n",
    "test_df  = test_df.sort_values('TransactionID')\n",
    "\n",
    "train_df = train_df.reset_index(drop = True)\n",
    "test_df  = test_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = train_df[target]\n",
    "del train_df[target]\n",
    "del test_df[target]\n",
    "g = train_df['DT_M']\n",
    "#del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train shape: (590540, 48)\n",
      "- Test shape: (506691, 48)\n"
     ]
    }
   ],
   "source": [
    "### IMPORT OOF PREDS\n",
    "\n",
    "# which model to stack?\n",
    "#model = 'lgb'\n",
    "\n",
    "# threshold\n",
    "#min_auc = 90\n",
    "\n",
    "# list names\n",
    "names = sorted(os.listdir('../oof_preds'))\n",
    "#names = [n for n in names if int(n[n.rindex('_')+1:-7]) > min_auc]\n",
    "#names = [s for s in names if model in s]\n",
    "\n",
    "# preprocessing loop\n",
    "for name in names:\n",
    "\n",
    "    # load preds\n",
    "    tmp_tr = pd.read_csv('../oof_preds/'   + str(name))\n",
    "    tmp_te = pd.read_csv('../submissions/' + str(name))\n",
    "\n",
    "    # sort preds by ID\n",
    "    tmp_tr = tmp_tr.sort_values('TransactionID')\n",
    "    tmp_te = tmp_te.sort_values('TransactionID')\n",
    "\n",
    "    \n",
    "    # cbind data\n",
    "    if name == names[0]:  \n",
    "        \n",
    "        tmp_tr.columns = ['TransactionID', name]    \n",
    "        tmp_te.columns = ['TransactionID', name]    \n",
    "        train = tmp_tr \n",
    "        test  = tmp_te\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        del tmp_tr['TransactionID'], tmp_te['TransactionID']\n",
    "        tmp_tr.columns = [name]    \n",
    "        tmp_te.columns = [name]    \n",
    "        train = pd.concat([train, tmp_tr], axis = 1)\n",
    "        test  = pd.concat([test,  tmp_te], axis = 1)\n",
    "    \n",
    "    '''\n",
    "    del tmp_tr['TransactionID'], tmp_te['TransactionID']\n",
    "    tmp_tr.columns = [name]    \n",
    "    tmp_te.columns = [name]    \n",
    "    train = pd.concat([train, tmp_tr], axis = 1)\n",
    "    test  = pd.concat([test,  tmp_te], axis = 1)\n",
    "    '''\n",
    "        \n",
    "# display information\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#train['max'] = train.filter(like = 'csv').max(axis = 1)\n",
    "#train['min'] = train.filter(like = 'csv').min(axis = 1)\n",
    "train['std'] = train.filter(like = 'csv').std(axis = 1)\n",
    "\n",
    "#test['max'] = test.filter(like = 'csv').max(axis = 1)\n",
    "#test['min'] = test.filter(like = 'csv').min(axis = 1)\n",
    "test['std'] = test.filter(like = 'csv').std(axis = 1)\n",
    "\n",
    "# display information\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### ADD FEATURES\n",
    "\n",
    "feats = []\n",
    "\n",
    "train = pd.concat([train, train_df[feats]], axis = 1)\n",
    "test  = pd.concat([test,  test_df[feats]],  axis = 1)\n",
    "\n",
    "#for var in feats:\n",
    "#    train[var] = train[var].astype('float')\n",
    "#    test[var]  = test[var].astype('float')\n",
    "\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### DROP CORRELATED PREDICTIONS\n",
    "\n",
    "# threshold\n",
    "top_p = 0.95\n",
    "\n",
    "# error-based sort\n",
    "col_idx = list(np.argsort([l[-9:-4] for l in list(train.columns)]))\n",
    "train   = train[train.columns[col_idx]]\n",
    "\n",
    "# create correlation matrix\n",
    "corr_matrix = train.rank().corr().abs()\n",
    "lower       = corr_matrix.where(np.tril(np.ones(corr_matrix.shape), k = -1).astype(np.bool))\n",
    "\n",
    "# subset \n",
    "to_drop  = [column for column in lower.columns if any(lower[column] > top_p)]\n",
    "features = [f for f in train.columns if f not in to_drop]\n",
    "print(train.shape)\n",
    "train = train[features]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 47)\n"
     ]
    }
   ],
   "source": [
    "# drop bad features\n",
    "excluded_feats = ['TransactionID', 'DT_M']\n",
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynozDG6yivwQ"
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# settings\n",
    "cores = 24\n",
    "seed  = 999\n",
    "\n",
    "# cross-validation\n",
    "num_folds = 6\n",
    "shuffle   = True\n",
    "\n",
    "# muner of rounds\n",
    "max_rounds = 10000\n",
    "stopping   = 100\n",
    "verbose    = 100\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':     'gbdt',\n",
    "    'objective':         'binary',\n",
    "    'metric':            'auc',\n",
    "    'bagging_fraction':  0.9,\n",
    "    'feature_fraction':  0.9,\n",
    "    'lambda_l1':         0.1,\n",
    "    'lambda_l2':         0.1,\n",
    "    'min_split_gain':    0,\n",
    "    'min_child_weight':  0.1,\n",
    "    'min_child_samples': 20,\n",
    "    'silent':            True,\n",
    "    'verbosity':         -1,\n",
    "    'learning_rate':     0.001,\n",
    "    'max_depth':         -1,\n",
    "    'num_leaves':        64,\n",
    "    'scale_pos_weight':  1,\n",
    "    'n_estimators':      max_rounds,\n",
    "    'nthread' :          cores,\n",
    "    'random_state':      seed,\n",
    "}\n",
    "\n",
    "'''\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':cores,\n",
    "                    'learning_rate':0.005,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.8,\n",
    "                    'n_estimators':10000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': seed,\n",
    "                } \n",
    "'''\n",
    "\n",
    "# data partitinoing\n",
    "#folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n",
    "folds = GroupKFold(n_splits = num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders\n",
    "clfs = []\n",
    "preds_test   = np.zeros(test.shape[0])\n",
    "preds_oof    = np.zeros(train.shape[0])\n",
    "importances  = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (453219, 47) (137321, 47)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.953215\tvalid_1's auc: 0.924427\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's auc: 0.953117\tvalid_1's auc: 0.924596\n",
      "----------------------\n",
      "FOLD 1: AUC = 0.924596\n",
      "----------------------\n",
      "\n",
      "Data shape: (488908, 47) (101632, 47)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.948574\tvalid_1's auc: 0.947596\n",
      "[200]\ttraining's auc: 0.950332\tvalid_1's auc: 0.949372\n",
      "[300]\ttraining's auc: 0.951156\tvalid_1's auc: 0.949724\n",
      "[400]\ttraining's auc: 0.951916\tvalid_1's auc: 0.949975\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttraining's auc: 0.951883\tvalid_1's auc: 0.949982\n",
      "----------------------\n",
      "FOLD 2: AUC = 0.949982\n",
      "----------------------\n",
      "\n",
      "Data shape: (497955, 47) (92585, 47)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.948662\tvalid_1's auc: 0.946709\n",
      "[200]\ttraining's auc: 0.950077\tvalid_1's auc: 0.94845\n",
      "[300]\ttraining's auc: 0.950974\tvalid_1's auc: 0.948932\n",
      "Early stopping, best iteration is:\n",
      "[274]\ttraining's auc: 0.950822\tvalid_1's auc: 0.948967\n",
      "----------------------\n",
      "FOLD 3: AUC = 0.948967\n",
      "----------------------\n",
      "\n",
      "Data shape: (501214, 47) (89326, 47)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.949685\tvalid_1's auc: 0.945856\n",
      "[200]\ttraining's auc: 0.950955\tvalid_1's auc: 0.946768\n",
      "[300]\ttraining's auc: 0.951675\tvalid_1's auc: 0.947095\n",
      "[400]\ttraining's auc: 0.952341\tvalid_1's auc: 0.947287\n",
      "[500]\ttraining's auc: 0.952722\tvalid_1's auc: 0.94715\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttraining's auc: 0.952359\tvalid_1's auc: 0.947295\n",
      "----------------------\n",
      "FOLD 4: AUC = 0.947295\n",
      "----------------------\n",
      "\n",
      "Data shape: (504519, 47) (86021, 47)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.947532\tvalid_1's auc: 0.954632\n",
      "[200]\ttraining's auc: 0.950043\tvalid_1's auc: 0.955412\n",
      "[300]\ttraining's auc: 0.950799\tvalid_1's auc: 0.955665\n",
      "[400]\ttraining's auc: 0.951296\tvalid_1's auc: 0.955782\n",
      "[500]\ttraining's auc: 0.951569\tvalid_1's auc: 0.955832\n",
      "[600]\ttraining's auc: 0.951896\tvalid_1's auc: 0.955893\n",
      "[700]\ttraining's auc: 0.952261\tvalid_1's auc: 0.955913\n",
      "[800]\ttraining's auc: 0.952632\tvalid_1's auc: 0.955962\n",
      "[900]\ttraining's auc: 0.953007\tvalid_1's auc: 0.955973\n",
      "[1000]\ttraining's auc: 0.953501\tvalid_1's auc: 0.956044\n",
      "[1100]\ttraining's auc: 0.953911\tvalid_1's auc: 0.956102\n",
      "[1200]\ttraining's auc: 0.954433\tvalid_1's auc: 0.956167\n",
      "[1300]\ttraining's auc: 0.954793\tvalid_1's auc: 0.95617\n",
      "[1400]\ttraining's auc: 0.955072\tvalid_1's auc: 0.956195\n",
      "[1500]\ttraining's auc: 0.955722\tvalid_1's auc: 0.956401\n",
      "[1600]\ttraining's auc: 0.956128\tvalid_1's auc: 0.956387\n",
      "Early stopping, best iteration is:\n",
      "[1531]\ttraining's auc: 0.955855\tvalid_1's auc: 0.956412\n",
      "----------------------\n",
      "FOLD 5: AUC = 0.956412\n",
      "----------------------\n",
      "\n",
      "Data shape: (506885, 47) (83655, 47)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.947213\tvalid_1's auc: 0.958231\n",
      "[200]\ttraining's auc: 0.94893\tvalid_1's auc: 0.959577\n",
      "[300]\ttraining's auc: 0.949963\tvalid_1's auc: 0.960018\n",
      "[400]\ttraining's auc: 0.950531\tvalid_1's auc: 0.960119\n",
      "[500]\ttraining's auc: 0.950885\tvalid_1's auc: 0.96011\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's auc: 0.950535\tvalid_1's auc: 0.960119\n",
      "----------------------\n",
      "FOLD 6: AUC = 0.960119\n",
      "----------------------\n",
      "\n",
      "--------------------------------\n",
      "- OOF AUC = 0.927000\n",
      "- CV TIME = 3.10 min\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "### CROSS-VALIDATION LOOP\n",
    "cv_start  = time.time()\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y, groups = g)):\n",
    "    \n",
    "    # data partitioning\n",
    "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # label encoding\n",
    "    trn_x, val_x, test_x = label_encoding(trn_x, val_x, test[features])\n",
    "    \n",
    "    # print data dimensions\n",
    "    print('Data shape:', trn_x.shape, val_x.shape)\n",
    "           \n",
    "    # train lightGBM\n",
    "    clf = lgb.LGBMClassifier(**lgb_params) \n",
    "    clf = clf.fit(trn_x, trn_y, \n",
    "                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n",
    "                  eval_metric           = \"auc\", \n",
    "                  early_stopping_rounds = stopping,\n",
    "                  verbose               = verbose)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "    # predict validation from the best iteration\n",
    "    best_iter = clf.best_iteration_\n",
    "       \n",
    "    # predictions\n",
    "    preds_oof[val_idx]    = clf.predict_proba(val_x,  num_iteration = best_iter)[:, 1]\n",
    "    preds_test           += clf.predict_proba(test_x, num_iteration = best_iter)[:, 1] / folds.n_splits \n",
    "\n",
    "    ## importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df['Feature'] = features\n",
    "    fold_importance_df['Importance'] = clf.feature_importances_\n",
    "    fold_importance_df['Fold'] = n_fold + 1\n",
    "    importances = pd.concat([importances, fold_importance_df], axis = 0)\n",
    "    \n",
    "    # print performance\n",
    "    print('----------------------')\n",
    "    print('FOLD%2d: AUC = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n",
    "    print('----------------------')\n",
    "    print('')\n",
    "        \n",
    "    # clear memory\n",
    "    #del trn_x, trn_y, val_x, val_y\n",
    "    #gc.collect()\n",
    "    \n",
    "    \n",
    "# print overall performance    \n",
    "cv_perf = roc_auc_score(y, preds_oof)\n",
    "print('--------------------------------')\n",
    "print('- OOF AUC = %.6f' % cv_perf)\n",
    "print('- CV TIME = {:.2f} min'.format((time.time() - cv_start) / 60))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927\n"
     ]
    }
   ],
   "source": [
    "############ RECHECK PERFORMANCE  \n",
    "\n",
    "# check performance\n",
    "print(np.round(roc_auc_score(y, preds_oof), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dsi_jeGG4VE"
   },
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Tt_FxCwG4VF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stack_lgb47_927'"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file name\n",
    "model = 'stack_lgb'\n",
    "perf  = str(round(cv_perf, 6))[2:7]\n",
    "name  = model + str(len(features)) + '_' + perf\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.023594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.023705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.023598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.023594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.023599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.023594\n",
       "1        3663550  0.023705\n",
       "2        3663551  0.023598\n",
       "3        3663552  0.023594\n",
       "4        3663553  0.023599"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export submission\n",
    "sub = pd.DataFrame({'TransactionID': test['TransactionID'], 'isFraud': preds_test})\n",
    "sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.9877730760217902, pvalue=0.0)"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check rank correlation with the best submission\n",
    "from scipy.stats import spearmanr\n",
    "sub  = sub.sort_values('TransactionID')\n",
    "best = pd.read_csv(\"../submissions/stack_lgb46_94648.csv\")\n",
    "best = best.sort_values('TransactionID')\n",
    "spearmanr(sub.isFraud, best.isFraud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
