{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA, FastICA, FactorAnalysis\n",
    "from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ HELPER FUNCTIONS\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ RANDOMNESS\n",
    "\n",
    "# seed function\n",
    "def seed_everything(seed = 23):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# set seed\n",
    "seed = 23\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1557933093757,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "7QV5eQHHG4Ud",
    "outputId": "2389881e-8c0a-4518-c185-d0a84d1d4a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 498)\n"
     ]
    }
   ],
   "source": [
    "# import CSV\n",
    "df = pd.read_pickle('../input/data_v8.pkl')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1334,
     "status": "ok",
     "timestamp": 1557933093762,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "hxJatDSBG4Uh",
    "outputId": "9b7dd4d7-fbf6-493b-d23c-25fdbf58ee37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 498)\n",
      "(506691, 498)\n"
     ]
    }
   ],
   "source": [
    "# partitioning\n",
    "train_df = df[df[target].isnull() == False]\n",
    "test_df  = df[df[target].isnull() == True]\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data\n",
    "train_df = train_df.sort_values('TransactionID')\n",
    "test_df  = test_df.sort_values('TransactionID')\n",
    "\n",
    "train_df = train_df.reset_index(drop = True)\n",
    "test_df  = test_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = train_df[target]\n",
    "del train_df[target]\n",
    "del test_df[target]\n",
    "g = train_df['DT_M']\n",
    "#del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train shape: (590540, 10)\n",
      "- Test shape: (506691, 10)\n"
     ]
    }
   ],
   "source": [
    "### IMPORT OOF PREDS\n",
    "\n",
    "# which model to stack?\n",
    "#model = 'lgb'\n",
    "\n",
    "# threshold\n",
    "#min_auc = 90\n",
    "\n",
    "# list names\n",
    "names = sorted(os.listdir('../oof_preds_bad'))\n",
    "#names = [n for n in names if int(n[n.rindex('_')+1:-7]) > min_auc]\n",
    "#names = [s for s in names if model in s]\n",
    "\n",
    "# preprocessing loop\n",
    "for name in names:\n",
    "\n",
    "    # load preds\n",
    "    tmp_tr = pd.read_csv('../oof_preds_bad/'   + str(name))\n",
    "    tmp_te = pd.read_csv('../submissions/' + str(name))\n",
    "\n",
    "    # sort preds by ID\n",
    "    tmp_tr = tmp_tr.sort_values('TransactionID')\n",
    "    tmp_te = tmp_te.sort_values('TransactionID')\n",
    "\n",
    "    \n",
    "    # cbind data\n",
    "    if name == names[0]:  \n",
    "        \n",
    "        tmp_tr.columns = ['TransactionID', name]    \n",
    "        tmp_te.columns = ['TransactionID', name]    \n",
    "        train = tmp_tr \n",
    "        test  = tmp_te\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        del tmp_tr['TransactionID'], tmp_te['TransactionID']\n",
    "        tmp_tr.columns = [name]    \n",
    "        tmp_te.columns = [name]    \n",
    "        train = pd.concat([train, tmp_tr], axis = 1)\n",
    "        test  = pd.concat([test,  tmp_te], axis = 1)\n",
    "    \n",
    "    '''\n",
    "    del tmp_tr['TransactionID'], tmp_te['TransactionID']\n",
    "    tmp_tr.columns = [name]    \n",
    "    tmp_te.columns = [name]    \n",
    "    train = pd.concat([train, tmp_tr], axis = 1)\n",
    "    test  = pd.concat([test,  tmp_te], axis = 1)\n",
    "    '''\n",
    "        \n",
    "# display information\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#train['max'] = train.filter(like = 'csv').max(axis = 1)\n",
    "#train['min'] = train.filter(like = 'csv').min(axis = 1)\n",
    "train['std'] = train.filter(like = 'csv').std(axis = 1)\n",
    "\n",
    "#test['max'] = test.filter(like = 'csv').max(axis = 1)\n",
    "#test['min'] = test.filter(like = 'csv').min(axis = 1)\n",
    "test['std'] = test.filter(like = 'csv').std(axis = 1)\n",
    "\n",
    "# display information\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### ADD FEATURES\n",
    "\n",
    "feats = []\n",
    "\n",
    "train = pd.concat([train, train_df[feats]], axis = 1)\n",
    "test  = pd.concat([test,  test_df[feats]],  axis = 1)\n",
    "\n",
    "#for var in feats:\n",
    "#    train[var] = train[var].astype('float')\n",
    "#    test[var]  = test[var].astype('float')\n",
    "\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### DROP CORRELATED PREDICTIONS\n",
    "\n",
    "# threshold\n",
    "top_p = 0.95\n",
    "\n",
    "# error-based sort\n",
    "col_idx = list(np.argsort([l[-9:-4] for l in list(train.columns)]))\n",
    "train   = train[train.columns[col_idx]]\n",
    "\n",
    "# create correlation matrix\n",
    "corr_matrix = train.rank().corr().abs()\n",
    "lower       = corr_matrix.where(np.tril(np.ones(corr_matrix.shape), k = -1).astype(np.bool))\n",
    "\n",
    "# subset \n",
    "to_drop  = [column for column in lower.columns if any(lower[column] > top_p)]\n",
    "features = [f for f in train.columns if f not in to_drop]\n",
    "print(train.shape)\n",
    "train = train[features]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 9)\n"
     ]
    }
   ],
   "source": [
    "# drop bad features\n",
    "excluded_feats = ['TransactionID', 'DT_M']\n",
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynozDG6yivwQ"
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# settings\n",
    "cores = 24\n",
    "seed  = 999\n",
    "\n",
    "# cross-validation\n",
    "num_folds = 6\n",
    "shuffle   = True\n",
    "\n",
    "# muner of rounds\n",
    "max_rounds = 1000\n",
    "stopping   = 100\n",
    "verbose    = 100\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':     'gbdt',\n",
    "    'objective':         'binary',\n",
    "    'metric':            'auc',\n",
    "    'bagging_fraction':  0.9,\n",
    "    'feature_fraction':  0.9,\n",
    "    'lambda_l1':         0.1,\n",
    "    'lambda_l2':         0.1,\n",
    "    'min_split_gain':    0,\n",
    "    'min_child_weight':  0.1,\n",
    "    'min_child_samples': 20,\n",
    "    'silent':            True,\n",
    "    'verbosity':         -1,\n",
    "    'learning_rate':     0.1,\n",
    "    'max_depth':         5,\n",
    "    'num_leaves':        50,\n",
    "    'scale_pos_weight':  1,\n",
    "    'n_estimators':      max_rounds,\n",
    "    'nthread' :          cores,\n",
    "    'random_state':      seed,\n",
    "}\n",
    "\n",
    "'''\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':cores,\n",
    "                    'learning_rate':0.005,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.8,\n",
    "                    'n_estimators':10000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': seed,\n",
    "                } \n",
    "'''\n",
    "\n",
    "# data partitinoing\n",
    "#folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n",
    "folds = GroupKFold(n_splits = num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders\n",
    "clfs = []\n",
    "preds_test   = np.zeros(test.shape[0])\n",
    "preds_oof    = np.zeros(train.shape[0])\n",
    "importances  = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (453219, 9) (137321, 9)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.959273\tvalid_1's auc: 0.917907\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's auc: 0.957587\tvalid_1's auc: 0.919502\n",
      "----------------------\n",
      "FOLD 1: AUC = 0.919502\n",
      "----------------------\n",
      "\n",
      "Data shape: (488908, 9) (101632, 9)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.955403\tvalid_1's auc: 0.938265\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.947528\tvalid_1's auc: 0.948436\n",
      "----------------------\n",
      "FOLD 2: AUC = 0.948436\n",
      "----------------------\n",
      "\n",
      "Data shape: (497955, 9) (92585, 9)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.955264\tvalid_1's auc: 0.947785\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's auc: 0.947193\tvalid_1's auc: 0.948268\n",
      "----------------------\n",
      "FOLD 3: AUC = 0.948268\n",
      "----------------------\n",
      "\n",
      "Data shape: (501214, 9) (89326, 9)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.955318\tvalid_1's auc: 0.940047\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's auc: 0.948221\tvalid_1's auc: 0.944876\n",
      "----------------------\n",
      "FOLD 4: AUC = 0.944876\n",
      "----------------------\n",
      "\n",
      "Data shape: (504519, 9) (86021, 9)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.953702\tvalid_1's auc: 0.928533\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.94782\tvalid_1's auc: 0.953353\n",
      "----------------------\n",
      "FOLD 5: AUC = 0.953353\n",
      "----------------------\n",
      "\n",
      "Data shape: (506885, 9) (83655, 9)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.953038\tvalid_1's auc: 0.959911\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.947082\tvalid_1's auc: 0.960339\n",
      "----------------------\n",
      "FOLD 6: AUC = 0.960339\n",
      "----------------------\n",
      "\n",
      "--------------------------------\n",
      "- OOF AUC = 0.930622\n",
      "- CV TIME = 9.77 min\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "### CROSS-VALIDATION LOOP\n",
    "cv_start  = time.time()\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y, groups = g)):\n",
    "    \n",
    "    # data partitioning\n",
    "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # label encoding\n",
    "    trn_x, val_x, test_x = label_encoding(trn_x, val_x, test[features])\n",
    "    \n",
    "    # print data dimensions\n",
    "    print('Data shape:', trn_x.shape, val_x.shape)\n",
    "           \n",
    "    # train lightGBM\n",
    "    clf = lgb.LGBMClassifier(**lgb_params) \n",
    "    clf = clf.fit(trn_x, trn_y, \n",
    "                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n",
    "                  eval_metric           = \"auc\", \n",
    "                  early_stopping_rounds = stopping,\n",
    "                  verbose               = verbose)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "    # predict validation from the best iteration\n",
    "    best_iter = clf.best_iteration_\n",
    "       \n",
    "    # predictions\n",
    "    preds_oof[val_idx]    = clf.predict_proba(val_x,  num_iteration = best_iter)[:, 1]\n",
    "    preds_test           += clf.predict_proba(test_x, num_iteration = best_iter)[:, 1] / folds.n_splits \n",
    "\n",
    "    ## importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df['Feature'] = features\n",
    "    fold_importance_df['Importance'] = clf.feature_importances_\n",
    "    fold_importance_df['Fold'] = n_fold + 1\n",
    "    importances = pd.concat([importances, fold_importance_df], axis = 0)\n",
    "    \n",
    "    # print performance\n",
    "    print('----------------------')\n",
    "    print('FOLD%2d: AUC = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n",
    "    print('----------------------')\n",
    "    print('')\n",
    "        \n",
    "    # clear memory\n",
    "    #del trn_x, trn_y, val_x, val_y\n",
    "    #gc.collect()\n",
    "    \n",
    "    \n",
    "# print overall performance    \n",
    "cv_perf = roc_auc_score(y, preds_oof)\n",
    "print('--------------------------------')\n",
    "print('- OOF AUC = %.6f' % cv_perf)\n",
    "print('- CV TIME = {:.2f} min'.format((time.time() - cv_start) / 60))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93062\n"
     ]
    }
   ],
   "source": [
    "############ RECHECK PERFORMANCE  \n",
    "\n",
    "# check performance\n",
    "print(np.round(roc_auc_score(y, preds_oof), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dsi_jeGG4VE"
   },
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Tt_FxCwG4VF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stack_lgb_bad9_93062'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file name\n",
    "model = 'stack_lgb_bad'\n",
    "perf  = str(round(cv_perf, 6))[2:7]\n",
    "name  = model + str(len(features)) + '_' + perf\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.013381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.013924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.013378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.013381\n",
       "1        3663550  0.013924\n",
       "2        3663551  0.014151\n",
       "3        3663552  0.013400\n",
       "4        3663553  0.013378"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export submission\n",
    "sub = pd.DataFrame({'TransactionID': test['TransactionID'], 'isFraud': preds_test})\n",
    "sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0.013817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0.010510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0.020645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0.007800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        2987000  0.013817\n",
       "1        2987001  0.010510\n",
       "2        2987002  0.020645\n",
       "3        2987003  0.004615\n",
       "4        2987004  0.007800"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export submission\n",
    "sub = pd.DataFrame({'TransactionID': train['TransactionID'], 'isFraud': preds_oof})\n",
    "sub.to_csv('../oof_preds/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-9525aec4486f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../submissions/stack_lgb46_94648.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TransactionID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mspearmanr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misFraud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misFraud\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\python3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36mspearmanr\u001b[1;34m(a, b, axis, nan_policy)\u001b[0m\n\u001b[0;32m   3322\u001b[0m         \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_chk_asarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3323\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxisout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3324\u001b[1;33m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3325\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3326\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\python3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "# check rank correlation with the best submission\n",
    "from scipy.stats import spearmanr\n",
    "sub  = sub.sort_values('TransactionID')\n",
    "best = pd.read_csv(\"../submissions/stack_lgb46_94648.csv\")\n",
    "best = best.sort_values('TransactionID')\n",
    "spearmanr(sub.isFraud, best.isFraud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
