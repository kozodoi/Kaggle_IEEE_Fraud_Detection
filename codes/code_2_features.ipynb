{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ HELPER FUNCTIONS\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ RANDOMNESS\n",
    "\n",
    "# seed function\n",
    "def seed_everything(seed = 23):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# set seed\n",
    "seed = 23\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1557933093757,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "7QV5eQHHG4Ud",
    "outputId": "2389881e-8c0a-4518-c185-d0a84d1d4a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 434)\n"
     ]
    }
   ],
   "source": [
    "# import CSV\n",
    "df = pd.read_pickle('../input/data.pkl')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfsTSMBAG4Uf"
   },
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 434)\n",
      "(1097231, 439)\n"
     ]
    }
   ],
   "source": [
    "############ E-MAIL DOMAINS\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', 'optonline.net': 'other',\n",
    "          'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n",
    "          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', 'hotmail.de': 'microsoft',\n",
    "          'centurylink.net': 'centurylink', 'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', \n",
    "          'gmx.de': 'other', 'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other',\n",
    "          'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo',\n",
    "          'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n",
    "          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo',\n",
    "          'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', 'frontier.com': 'yahoo',\n",
    "          'anonymous.com': 'other', 'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo',\n",
    "          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other',\n",
    "          'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', 'mac.com': 'apple',\n",
    "          'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', 'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other',\n",
    "          'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n",
    "us_emails = ['gmail', 'net', 'edu']\n",
    "\n",
    "for c in ['P_emaildomain', 'R_emaildomain']:\n",
    "    df[c + '_bin']    = df[c].map(emails)\n",
    "    df[c + '_suffix'] = df[c].map(lambda x: str(x).split('.')[-1])\n",
    "    df[c + '_suffix'] = df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
    "    df[c + '_prefix'] = df[c].apply(lambda x: str(x).split('.')[0])\n",
    "    \n",
    "\n",
    "df['P_emaildomain'] = df['P_emaildomain'].fillna('unknown')\n",
    "df['R_emaildomain'] = df['R_emaildomain'].fillna('unknown')\n",
    "    \n",
    "df['email_match'] = np.where((df['P_emaildomain'] == df['R_emaildomain']) & (df['P_emaildomain'] != 'unknown'), 1, 0)\n",
    "    \n",
    "del df['P_emaildomain'], df['R_emaildomain']\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 439)\n",
      "(1097231, 440)\n"
     ]
    }
   ],
   "source": [
    "############ DEVICE TYPE\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df['DeviceInfo']  = df['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "df['device_name'] = df['DeviceInfo'].str.split('/', expand = True)[0]\n",
    "\n",
    "df.loc[df['device_name'].str.contains('SM', na=False),      'device_name'] = 'Samsung'\n",
    "df.loc[df['device_name'].str.contains('sm', na=False),      'device_name'] = 'Samsung'\n",
    "df.loc[df['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n",
    "df.loc[df['device_name'].str.contains('GT-', na=False),     'device_name'] = 'Samsung'\n",
    "df.loc[df['device_name'].str.contains('Moto G', na=False),  'device_name'] = 'Motorola'\n",
    "df.loc[df['device_name'].str.contains('Moto', na=False),    'device_name'] = 'Motorola'\n",
    "df.loc[df['device_name'].str.contains('moto', na=False),    'device_name'] = 'Motorola'\n",
    "df.loc[df['device_name'].str.contains('LG-', na=False),     'device_name'] = 'LG'\n",
    "df.loc[df['device_name'].str.contains('lg-', na=False),     'device_name'] = 'LG'\n",
    "df.loc[df['device_name'].str.contains('rv:', na=False),     'device_name'] = 'RV'\n",
    "df.loc[df['device_name'].str.contains('HUAWEI', na=False),  'device_name'] = 'Huawei'\n",
    "df.loc[df['device_name'].str.contains('huawei', na=False),  'device_name'] = 'Huawei'\n",
    "df.loc[df['device_name'].str.contains('ALE-', na=False),    'device_name'] = 'Huawei'\n",
    "df.loc[df['device_name'].str.contains('ale-', na=False),    'device_name'] = 'Huawei'\n",
    "df.loc[df['device_name'].str.contains('ane-', na=False),    'device_name'] = 'Huawei'\n",
    "df.loc[df['device_name'].str.contains('cam-', na=False),    'device_name'] = 'Huawei'\n",
    "df.loc[df['device_name'].str.contains('rne-', na=False),    'device_name'] = 'Huawei'\n",
    "df.loc[df['device_name'].str.contains('pra-', na=False),    'device_name'] = 'Huawei'\n",
    "df.loc[df['device_name'].str.contains('-L', na=False),      'device_name'] = 'Huawei'\n",
    "df.loc[df['device_name'].str.contains('Blade', na=False),   'device_name'] = 'ZTE'\n",
    "df.loc[df['device_name'].str.contains('BLADE', na=False),   'device_name'] = 'ZTE'\n",
    "df.loc[df['device_name'].str.contains('blade', na=False),   'device_name'] = 'ZTE'\n",
    "df.loc[df['device_name'].str.contains('Linux', na=False),   'device_name'] = 'Linux'\n",
    "df.loc[df['device_name'].str.contains('linux', na=False),   'device_name'] = 'Linux'\n",
    "df.loc[df['device_name'].str.contains('XT', na=False),      'device_name'] = 'Sony'\n",
    "df.loc[df['device_name'].str.contains('xt', na=False),      'device_name'] = 'Sony'\n",
    "df.loc[df['device_name'].str.contains('HTC', na=False),     'device_name'] = 'HTC'\n",
    "df.loc[df['device_name'].str.contains('htc', na=False),     'device_name'] = 'HTC'\n",
    "df.loc[df['device_name'].str.contains('ASUS', na=False),    'device_name'] = 'Asus'\n",
    "df.loc[df['device_name'].str.contains('asus', na=False),    'device_name'] = 'Asus'\n",
    "\n",
    "df.loc[df.device_name.isin(df.device_name.value_counts()[df.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n",
    "\n",
    "#del df['DeviceInfo']\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 440)\n",
      "(1097231, 441)\n"
     ]
    }
   ],
   "source": [
    "############ OPERATING SYSTEM\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df['operating_system'] = np.NaN\n",
    "\n",
    "df.loc[df['id_30'].str.contains('Windows', na = False), 'operating_system']  = 'Windows'\n",
    "df.loc[df['id_30'].str.contains('iOS',     na = False), 'operating_system']  = 'iOS'\n",
    "df.loc[df['id_30'].str.contains('Mac OS',  na = False), 'operating_system']  = 'MacOS'\n",
    "df.loc[df['id_30'].str.contains('Android', na = False), 'operating_system']  = 'Android'\n",
    "df.loc[df['id_30'].str.contains('Linux',   na = False), 'operating_system']  = 'Linux'\n",
    "\n",
    "df.loc[df['operating_system'].isnull(), 'operating_system'] = \"Other\"\n",
    "df.loc[df['id_30'].isnull(),            'operating_system'] = \"Unknown\"\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 441)\n",
      "(1097231, 442)\n"
     ]
    }
   ],
   "source": [
    "############ BROWSER TYPE\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df['browser_type'] = np.NaN\n",
    "\n",
    "df.loc[df['id_31'].str.contains('android', na = False),   'browser_type']  = 'Android'\n",
    "df.loc[df['id_31'].str.contains('chrome', na = False),    'browser_type']  = 'Chrome'\n",
    "df.loc[df['id_31'].str.contains('opera',     na = False), 'browser_type']  = 'Opera'\n",
    "df.loc[df['id_31'].str.contains('edge',  na = False),     'browser_type']  = 'Edge'\n",
    "df.loc[df['id_31'].str.contains('firefox', na = False),   'browser_type']  = 'Firefox'\n",
    "df.loc[df['id_31'].str.contains('safari', na = False),    'browser_type']  = 'Safari'\n",
    "df.loc[df['id_31'].str.contains('samsung', na = False),   'browser_type']  = 'Samsung'\n",
    "df.loc[df['id_31'].str.contains('ie', na = False),        'browser_type']  = 'Internet Explorer'\n",
    "df.loc[df['id_31'].str.contains('google', na = False),    'browser_type']  = 'Google Search'\n",
    "\n",
    "df.loc[df['browser_type'].isnull(), 'browser_type'] = \"Other\"\n",
    "df.loc[df['id_31'].isnull(),        'browser_type'] = \"Unknown\"\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 442)\n",
      "(1097231, 443)\n"
     ]
    }
   ],
   "source": [
    "############ BROWSER VERSION\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df['lastest_browser'] = np.zeros(df.shape[0])\n",
    "\n",
    "df.loc[df[\"id_31\"] == \"samsung browser 7.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"opera 53.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"mobile safari 10.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"google search application 49.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"firefox 60.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"edge 17.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 69.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 67.0 for android\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 63.0 for android\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 63.0 for ios\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 64.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 64.0 for android\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 64.0 for ios\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 65.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 65.0 for android\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 65.0 for ios\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 66.0\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 66.0 for android\",'lastest_browser']=1\n",
    "df.loc[df[\"id_31\"] == \"chrome 66.0 for ios\",'lastest_browser']=1\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 443)\n",
      "(1097231, 444)\n"
     ]
    }
   ],
   "source": [
    "############ NUMBER OF MATCHES\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "for var in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n",
    "    df[var].fillna('N', inplace = True)\n",
    "\n",
    "df['M'] = df.M1 + df.M2 + df.M3 + df.M5 + df.M6 + df.M7 + df.M8 + df.M9\n",
    "df['num_matches'] = df['M'].str.count('T')\n",
    "del df['M']\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 444)\n",
      "(1097231, 445)\n"
     ]
    }
   ],
   "source": [
    "############ RESOLUTION\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df['pixels'] = df['id_33'].str.split('x', expand = True)[0].fillna(0).astype('int') * df['id_33'].str.split('x', expand = True)[1].fillna(0).astype('int') / 100000\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 445)\n",
      "(1097231, 447)\n"
     ]
    }
   ],
   "source": [
    "############ AMOUNT\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df['TransactionAmt_dollars'] = df['TransactionAmt'].astype('str').str.split('.', expand = True)[0]\n",
    "df['TransactionAmt_cents']   = df['TransactionAmt'].astype('str').str.split('.', expand = True)[1]\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 447)\n",
      "(1097231, 453)\n"
     ]
    }
   ],
   "source": [
    "############ DATES\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "start_date = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\n",
    "\n",
    "df['TransactionDT'] = df['TransactionDT'].fillna(df['TransactionDT'].median())\n",
    "\n",
    "df['DT']    = df['TransactionDT'].apply(lambda x: (start_date + datetime.timedelta(seconds = x)))\n",
    "df['DT_H']  = df['DT'].dt.hour.astype('object')\n",
    "df['DT_DW'] = df['DT'].dt.dayofweek.astype('object')\n",
    "df['DT_D']  = (df['DT'].dt.year - 2017)*365 + df['DT'].dt.dayofyear.astype('object')\n",
    "df['DT_W']  = (df['DT'].dt.year - 2017)*52  + df['DT'].dt.weekofyear.astype('object')\n",
    "df['DT_M']  = (df['DT'].dt.year - 2017)*12  + df['DT'].dt.month.astype('object')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "############ DISTANCE\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df['dist'] = df['dist1']\n",
    "df['dist'][df['dist1'].isnull()] = df['dist2'][df['dist1'].isnull()]\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 453)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (12, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (608, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (19311, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (7, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (365, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (24, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (5, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (17091, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (502, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (134, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (5, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (2, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (11, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (7, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (16, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (442, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (94, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (60, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (60, 6)\n",
      "- Preparing the dataset...\n",
      "- Extracted 0 factors and 1 numerics...\n",
      "- Aggregating numeric features...\n",
      "- Final dimensions: (36, 6)\n",
      "(1097231, 556)\n"
     ]
    }
   ],
   "source": [
    "############ TRANSACTION AMOUNT\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "# take logs\n",
    "df['TransactionAmt'] = np.log1p(df['TransactionAmt'])\n",
    "\n",
    "# new group indicators\n",
    "df['DT_M_ProductCD']  = df['DT_M'].astype(str) + '_' + df['ProductCD'].astype(str)\n",
    "df['DT_M_card4']      = df['DT_M'].astype(str) + '_' + df['card4'].astype(str)\n",
    "df['DT_M_DeviceType'] = df['DT_M'].astype(str) + '_' + df['DeviceType'].astype(str)\n",
    "df['address']         = df['addr1'].astype(str) + '_' + df['addr2'].astype(str)\n",
    "df['card']            = df['card1'].astype(str) + '_' + df['card2'].astype(str) + '_' + df['card3'].astype(str) + '_' + df['card4'].astype(str) + '_' + df['card5'].astype(str) + '_' + df['card6'].astype(str)\n",
    "df['product_type']    = df['TransactionAmt'].astype(str) + '_' + df['ProductCD'].astype(str)\n",
    "\n",
    "df['card1']  = df['card1'].astype(str)\n",
    "df['card2']  = df['card2'].astype(str)\n",
    "df['card3']  = df['card3'].astype(str)\n",
    "df['card4']  = df['card4'].astype(str)\n",
    "df['addr1']  = df['addr1'].astype(str)\n",
    "df['addr2']  = df['addr2'].astype(str)\n",
    "\n",
    "# aggregate by month or other features\n",
    "for uid in ['DT_M', 'address', 'card', 'DT_DW', 'DT_D', \"DT_H\", \n",
    "            'ProductCD', 'card1', 'card2', 'card3', 'card4', 'DeviceType', 'browser_type', 'operating_system', 'device_name', 'addr1', 'addr2',\n",
    "            'DT_M_ProductCD', 'DT_M_card4', 'DT_M_DeviceType']:\n",
    "    agg_df = aggregate_data(df[['TransactionAmt', uid]], group_var = uid, num_stats = ['mean', 'sum', 'min', 'max', 'std'], var_label = uid)\n",
    "    agg_df[uid] = agg_df[uid].astype('object')\n",
    "    df = df.merge(agg_df, how = 'left', on = uid)\n",
    "    del agg_df\n",
    "    \n",
    "# drop group indicators\n",
    "for uid in ['DT_M_ProductCD', 'DT_M_card4', 'DT_M_DeviceType']:\n",
    "    del df[uid]\n",
    "    \n",
    "# compute difference in means\n",
    "#for uid in ['DT_M', 'DT_M_ProductCD', 'DT_M_card4', 'DT_M_DeviceType']:\n",
    "#    df['TransactionAmt'] - df[uid + '_TransactionAmt_mean']\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 564)\n"
     ]
    }
   ],
   "source": [
    "# compute difference in means\n",
    "for uid in ['DT_M', 'DT_M_ProductCD', 'DT_M_card4', 'DT_M_DeviceType']:\n",
    "    df[uid + '_TransactionAmt_mean_dif1'] = df['TransactionAmt'] - df[uid + '_TransactionAmt_mean']\n",
    "    df[uid + '_TransactionAmt_mean_dif2'] = np.abs(df[uid + '_TransactionAmt_mean_dif1']) / df[uid + '_TransactionAmt_std']\n",
    "    \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 564)\n",
      "(1097231, 579)\n"
     ]
    }
   ],
   "source": [
    "############ COUNTS\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "for var in ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'address', 'card', 'product_type', 'id_30', 'id_31', 'id_33', 'DeviceInfo']:\n",
    "    temp = df[var].value_counts().to_dict()\n",
    "    df[var + '_counts'] = df[var].map(temp)\n",
    "    \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097231, 579)\n",
      "(1097231, 498)\n"
     ]
    }
   ],
   "source": [
    "############ REMOVE NOISY IDS\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "del df['id_30'], df['id_31'], df['id_33'], df['address'], df['card'], df['product_type'], df['DeviceInfo']\n",
    "\n",
    "drop_col = ['V300','V309','V111','V124','V106','V125','V315','V134','V102','V123','V316','V113',\n",
    "              'V136','V305','V110','V299','V289','V286','V318','V304','V116','V284','V293',\n",
    "              'V137','V295','V301','V104','V311','V115','V109','V119','V321','V114','V133','V122','V319',\n",
    "              'V105','V112','V118','V117','V121','V108','V135','V320','V303','V297','V120',\n",
    "              'V1','V14','V41','V65','V88', 'V89', 'V107', 'V68', 'V28', 'V27', 'V29', 'V241','V269',\n",
    "              'V240', 'V325', 'V138', 'V154', 'V153', 'V330', 'V142', 'V195', 'V302', 'V328', 'V327', \n",
    "              'V198', 'V196', 'V155']\n",
    "for var in drop_col:\n",
    "    del df[var]\n",
    "    \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1097231, 498)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export data\n",
    "df.to_pickle(\"../input/data_v8.pkl\")\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
